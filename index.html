<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dongki Jung</title>

  <meta name="author" content="Dongki Jung">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="image/icon_umd.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Dongki Jung</name>
                  </p>
                  <p> jdk9405@umd.edu &nbsp | &nbsp jdk9405@gmail.com
                  </p>
                    <p> I am a Computer Science Ph.D. student at <a href="https://www.cs.umd.edu/">University of Maryland, College Park</a> (UMD),
                      working with <a href="https://www.cs.umd.edu/people/dmanocha">Prof. Dinesh Manocha</a> at the <a href="https://gamma.umd.edu/">GAMMA Lab</a>.
                      At UMD, I've worked on 3D reconstruction and neural rendering.
                  <!-- <p>I joined <a href="https://www.naverlabs.com/">NAVER LABS</a> in April 2021. </a> -->
                  </p>
                  <p>
                      Previously, I was a research scientist at <a href="https://www.naverlabs.com/">NAVER LABS</a>. I've worked on visual localization and mapping for robotics.
                    <br>
                      I graduated with my MS at <a href="https://ee.kaist.ac.kr/">KAIST</a>, where I was advised by <a href="https://cilabs.kaist.ac.kr/members/professor">Changick Kim</a>.
                    <br>
                      I did my bachelors at the <a href="https://ee.korea.ac.kr/eng/main/main.html">Korea University</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:dongki.jung@naverlabs.com">Email</a> &nbsp/&nbsp
                    <a href="data/dongki_CV.pdf">CV</a> &nbsp/&nbsp
                    <!--                <a href="https://www.linkedin.com/in/jaehoon-choi-157709b5/">Linkedin</a> &nbsp/&nbsp-->
                    <a href="https://scholar.google.com/citations?user=MEwO0QwAAAAJ&hl=ko">Google Scholar</a>
                    &nbsp/&nbsp
                    <!--                <a href="https://twitter.com/jaehoonc44">Twitter</a>-->
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="image/dongki_face_crop.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="image/dongki_face_crop.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I'm interested in the research for combining classical geometry and recent deep learning methods for
                    3D vision.
<!--                     <br> -->
<!--                     &#x1F449<a href="https://sites.google.com/view/nstepresearchproject/%ED%99%88"><font color="red"><strong>Here is a summary of my research project!</strong></font></a> -->
                    <!--                Representative papers are <span class="highlight">highlighted</span>.-->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


<!-- Preprints -->




          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="uav4d_stop()" onmouseover="uav4d_start()">
                <heading>Preprints</heading>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='uav4d_image'>
                      <img src="image/uav4d.gif" width="190" >
                    </div>
                    <img src='image/uav4d.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function uav4d_start() {
                      document.getElementById('uav4d_image').style.opacity = "1";
                    }

                    function uav4d_stop() {
                      document.getElementById('uav4d_image').style.opacity = "0";
                    }
                    uav4d_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://www.arxiv.org/abs/2506.05011">
                    <papertitle>UAV4D: Dynamic Neural Rendering of Human-Centric UAV Imagery using Gaussian Splatting
                    </papertitle>
                  </a>
                  <br>
                  Jaehoon Choi, <strong><u>Dongki Jung</u></strong>, Christopher Maxey, Sungmin Eum, Yonghan Lee, Dinesh Manocha, and Heesung Kwon
                  <!-- <br> -->
                  <!-- <em>Accepted to ICRA</em> -->
                  <br>
                  <!-- <a href="">arXiv</a> -->
                  <a href="https://www.arxiv.org/abs/2506.05011">[arXiv]</a>
                  <a href="https://uav4d.github.io/">[Project]</a>
                  <br>
                    We introduce UAV4D, a framework for enabling photorealistic rendering for dynamic real-world scenes captured by UAVs.
                  <br>
                  <br>
                </td>
              </tr>


              <tr onmouseout="uavtwin_stop()" onmouseover="uavtwin_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='uavtwin_image'>
                      <br><br>
                      <img src="image/uavtwin.gif" width="195" >
                    </div>
                    <br><br>
                    <img src='image/uavtwin.png' width="195">
                  </div>
                  <script type="text/javascript">
                    function uavtwin_start() {
                      document.getElementById('uavtwin_image').style.opacity = "1";
                    }

                    function uavtwin_stop() {
                      document.getElementById('uavtwin_image').style.opacity = "0";
                    }
                    uavtwin_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/abs/2504.02158">
                    <papertitle>UAVTwin: Neural Digital Twins for UAVs using Gaussian Splatting
                    </papertitle>
                  </a>
                  <br>
                  Jaehoon Choi, <strong><u>Dongki Jung</u></strong>, Yonghan Lee, Sungmin Eum, Dinesh Manocha, and Heesung Kwon
                  <br>
                  <a href="https://arxiv.org/abs/2504.02158">[arXiv]</a>
                  <a href="https://uavgsim.github.io/">[Project]</a>
                  <br>
                    We present a method for creating digital twins from real-world environments and facilitating data augmentation for training downstream models embedded in unmanned aerial vehicles (UAVs).
                  </br>
                  <!-- <br><br><br> -->
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <tr onmouseout="modegs_stop()" onmouseover="modegs_start()">
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <div class="two" id='modegs_image'>
                            <img src="image/modegs.png" width="200">
                          </div>
                          <img src='image/modegs.png' width="200">
                        </div>
                        <script type="text/javascript">
                          function modegs_start() {
                            document.getElementById('modegs_image').style.opacity = "1";
                          }

                          function modegs_stop() {
                            document.getElementById('modegs_image').style.opacity = "0";
                          }
                          modegs_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a
                          href="https://arxiv.org/pdf/2410.04646">
                          <papertitle>Mode-GS: Monocular Depth Guided Anchored 3D Gaussian Splatting for Robust Ground-View Scene Rendering
                          </papertitle>
                        </a>
                        <br>
                        Yonghan Lee, Jaehoon Choi, <strong><u>Dongki Jung</u></strong>, Jaeseong Yun, Soohyun Ryu, Dinesh Manocha, and Suyong Yeon
                        <!-- <br> -->
                        <!-- <em>Accepted to ICRA</em> -->
                        <br>
                        <a href="https://arxiv.org/pdf/2410.04646">[arXiv]</a>
                        <br>
                        <p></p>
                        <p>
                          We propose a novel 3D Gaussian Splatting algorithm that integrates monocular depth network with anchored Gaussian Splatting, enabling robust rendering performance on sparse-view datasets.
                        </p>
                      </td>
                    </tr>
                </td>
              </tr>
 

            </tbody>
          </table>




<!-- Publications -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="rpg360_stop()" onmouseover="rpg360_start()">
                <heading>Publications</heading>
                <td style="padding:20px;width:25%;vertical-align:middle">
                <!-- <heading>Publications</heading> -->
                  <div class="one">
                    <div class="two" id='rpg360_image'>
                      <img src="image/rpg360_2.png" width="190" >
                    </div>
                    <img src='image/rpg360_1.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function rpg360_start() {
                      document.getElementById('rpg360_image').style.opacity = "1";
                    }

                    function rpg360_stop() {
                      document.getElementById('rpg360_image').style.opacity = "0";
                    }
                    rpg360_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/abs/2502.12545">
                    <papertitle>
                    RPG360: Robust 360 Depth Estimation with Perspective Foundation Models and Graph Optimization
                    </papertitle>
                  </a>
                  <br>
                  <strong><u>Dongki Jung</u></strong>, Jaehoon Choi, Yonghan Lee, Dinesh Manocha
                  <!-- <br> -->
                  <!-- <em>Accepted to ICRA</em> -->
                  <br>
                  <!-- <a href="">arXiv</a> -->
                  NeurIPS, 2025
                  <br>
                  <a href="https://jdk9405.github.io/RPG360/">[Project]</a>
                  <br>
                  RPG360 leverages the prior knowledge of the perspective foudnation model along with graph optimization, thereby enchances 3D structural awareness and achieves superior performance.
                  </br>
                </td>
              </tr>

              <tr onmouseout="im360_stop()" onmouseover="im360_start()">
                <heading>Publications</heading>
                <td style="padding:20px;width:25%;vertical-align:middle">
                <!-- <heading>Publications</heading> -->
                  <div class="one">
                    <div class="two" id='im360_image'>
                      <img src="image/im360_1.png" width="190" >
                    </div>
                    <img src='image/im360_1.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function im360_start() {
                      document.getElementById('im360_image').style.opacity = "1";
                    }

                    function im360_stop() {
                      document.getElementById('im360_image').style.opacity = "0";
                    }
                    im360_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/abs/2502.12545">
                    <papertitle>IM360: Large-scale Indoor Mapping with 360 Cameras
                    </papertitle>
                  </a>
                  <br>
                  <strong><u>Dongki Jung</u></strong>*, Jaehoon Choi*, Yonghan Lee, Dinesh Manocha
                  <!-- <br> -->
                  <!-- <em>Accepted to ICRA</em> -->
                  <br>
                  <!-- <a href="">arXiv</a> -->
                  ICCV, 2025
                  <br>
                  <a href="https://jdk9405.github.io/IM360/">[Project]</a>
                  <br>
                    We propose a complete pipeline for indoor mapping using omnidirectional images, consisting of three key stages: (1) Spherical SfM, (2) Neural Surface Reconstruction, and (3) Texture Optimization.
                  </br>
                </td>
              </tr>



              <tr onmouseout="edm_stop()" onmouseover="edm_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='edm_image'>
                      <img src="image/edm.png" width="195">
                    </div>
                    <img src='image/edm.png' width="195">
                  </div>
                  <script type="text/javascript">
                    function edm_start() {
                      document.getElementById('edm_image').style.opacity = "1";
                    }

                    function edm_stop() {
                      document.getElementById('edm_image').style.opacity = "0";
                    }
                    edm_stop()
                    We propose a novel 3D Gaussian Splatting algorithm that integrates monocular depth network with anchored Gaussian Splatting, enabling robust rendering performance on sparse-view datasets.
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/abs/2502.20685">
                    <papertitle>EDM: Equirectangular Projection-Oriented Dense Kernelized Feature Matching
                    </papertitle>
                  </a>
                  <br>
                  <strong><u>Dongki Jung</u></strong>, Jaehoon Choi, Yonghan Lee, Somi Jeong, Taejae Lee, Dinesh Manocha, Suyong Yeon 
                  <br>
                  CVPR, 2025
                  <!-- <em>Accepted to ICRA</em> -->
                  <br>
                  <a href="https://jdk9405.github.io/EDM/">[Project]</a>
                  <!-- <a href="https://arxiv.org/pdf/2410.04646">arXiv</a> -->
                  <br>
                  <!-- <p></p> -->
                  <!-- <p> -->
                    We propose the first learning-based dense matching algorithm for omnidirectional images.
                  <!-- </p> -->
                </td>
              </tr>

               
              <tr onmouseout="wayil_stop()" onmouseover="wayil_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='wayil_image'>
                      <img src="image/wayil.gif" width="200">
                    </div>
                    <img src='image/wayil_image_resize.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function wayil_start() {
                      document.getElementById('wayil_image').style.opacity = "1";
                    }

                    function wayil_stop() {
                      document.getElementById('wayil_image').style.opacity = "0";
                    }
                    wayil_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://rllab-snu.github.io/projects/WayIL/">
                    <papertitle>WayIL: Image-based Indoor Localization with Wayfinding Maps
                    </papertitle>
                  </a>
                  <br>
                  Obin Kwon, <strong><u>Dongki Jung</u></strong>, Youngji Kim, Soohyun Ryu, Suyong Yeon, Songhwai Oh, Donghwan Lee
                  <br>
                  <em>ICRA</em>, 2024
                  <!-- <br> -->
                               <!-- <a href="https://rllab.snu.ac.kr/publications/papers/2024_icra_wayil.pdf">arXiv</a> -->
                  <br>
                  <p></p>
                  <p>
                    We address robot localization in large-scale indoor environments using wayfinding maps.
                  </p>
                </td>
              </tr>

              <tr onmouseout="tmo_stop()" onmouseover="tmo_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='tmo_image'>
                      <img src="image/tmo_image_resize.png" width="200">
                    </div>
                    <img src='image/tmo_image_resize.png' width="200">
                  </div>
                  <script type="text/javascript">
                    function tmo_start() {
                      document.getElementById('tmo_image').style.opacity = "1";
                    }

                    function tmo_stop() {
                      document.getElementById('tmo_image').style.opacity = "0";
                    }
                    tmo_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_TMO_Textured_Mesh_Acquisition_of_Objects_With_a_Mobile_Device_CVPR_2023_paper.pdf">
                    <papertitle>TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable
                      Rendering
                    </papertitle>
                  </a>
                  <br>
                  Jaehoon Choi, <strong><u>Dongki Jung</u></strong>, Taejae Lee, Sangwook Kim, Youngdong Jung, Dinesh Manocha,
                  Donghwan Lee
                  <br>
                  <em>CVPR</em>, 2023
                  <br>
                  <a href="https://jh-choi.github.io/TMO/">[Project]</a>
                  <!--              <a href="https://arxiv.org/abs/2203.05332">arXiv</a>-->
                  <br>
                  <!-- <p></p> -->
                  <!-- <p> -->
                    We present a new pipeline for acquiring a textured mesh in the wild with a mobile device.
                  <!-- </p> -->
                </td>
              </tr>

              <tr onmouseout="selftune_stop()" onmouseover="selftune_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='selftune_image'>
                      <br>
                      <img src="image/selftune.gif" width="200">
                    </div>
                    <br>
                    <img src='image/selftune_resize.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function selftune_start() {
                      document.getElementById('selftune_image').style.opacity = "1";
                    }

                    function selftune_stop() {
                      document.getElementById('selftune_image').style.opacity = "0";
                    }
                    selftune_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.05332">
                    <papertitle>SelfTune: Metrically Scaled Monocular Depth Estimation through Self-Supervised Learning
                    </papertitle>
                  </a>
                  <br>
                  Jaehoon Choi*, <strong><u>Dongki Jung</u></strong>*, Yonghan Lee, Deokhwa Kim, Dinesh Manocha, Donghwan Lee
                  <br>
                  <em>ICRA</em>, 2022
                  <br>
                  <!--              <a href="https://arxiv.org/abs/2203.05332">arXiv</a>-->
                  <br>
                  <p></p>
                  <p>
                    We have developed a fine-tuning method for metrically accurate depth estimation in a self-supervised
                    way.
                  </p>
                </td>
              </tr>

              <tr onmouseout="dnd_stop()" onmouseover="dnd_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dnd_image'>
                      <!--                  <img src='image/DnD_resize.png' width="190"></div>-->
                      <br>
                      <img src="image/dnd.gif" width="190">
                    </div>
                    <br>
                    <img src='image/DnD_resize.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function dnd_start() {
                      document.getElementById('dnd_image').style.opacity = "1";
                    }

                    function dnd_stop() {
                      document.getElementById('dnd_image').style.opacity = "0";
                    }
                    dnd_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/ICCV2021/html/Jung_DnD_Dense_Depth_Estimation_in_Crowded_Dynamic_Indoor_Scenes_ICCV_2021_paper.html">
                    <papertitle>DnD: Dense Depth Estimation in Crowded Dynamic Indoor Scenes</papertitle>
                  </a>
                  <br>
                  <strong><u>Dongki Jung</u></strong>*, Jaehoon Choi*, Yonghan Lee, Deokhwa Kim, Changick Kim,
                  Dinesh Manocha,
                  Donghwan Lee
                  <br>
                  <em>ICCV</em>, 2021
                  <br>
                  <!--              <a href="https://arxiv.org/abs/2108.05615">arXiv</a>-->
                  <br>
                  <p></p>
                  <p>
                    We present a novel approach for estimating depth from a monocular camera as it moves through complex
                    and crowded indoor environments.
                  </p>
                </td>
              </tr>

              <tr onmouseout="smvs_stop()" onmouseover="smvs_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smvs_image'>
                      <img src='image/sparseMVS_resize.png' width="180">
                    </div>
                    <img src='image/sparseMVS_resize.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function smvs_start() {
                      document.getElementById('smvs_image').style.opacity = "1";
                    }

                    function smvs_stop() {
                      document.getElementById('smvs_image').style.opacity = "0";
                    }
                    smvs_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Just_a_Few_Points_Are_All_You_Need_for_Multi-View_ICCV_2021_paper.html">
                    <papertitle>Just a Few Points are All You Need for Multi-view Stereo: A Novel Semi-supervised
                      Learning Method for Multi-view Stereo</papertitle>
                  </a>
                  <br>
                  Taekyung Kim, Jaehoon Choi, Seokeon Choi, <strong><u>Dongki Jung</u></strong>, Changick Kim
                  <br>
                  <em>ICCV</em>, 2021
                  <br>
                  <!--              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Just_a_Few_Points_Are_All_You_Need_for_Multi-View_ICCV_2021_paper.html">arXiv</a>-->
                  <br>
                  <p></p>
                  <p>
                    We first introduce a novel semi-supervised multi-view stereo framework.
                  </p>
                </td>
              </tr>

              <tr onmouseout="selfdeco_stop()" onmouseover="selfdeco_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='selfdeco_image'>
                      <br>
                      <img src='image/selfdeco.PNG' width="190">
                    </div>
                    <br>
                    <img src='image/selfdeco.PNG' width="190">
                  </div>
                  <script type="text/javascript">
                    function selfdeco_start() {
                      document.getElementById('selfdeco_image').style.opacity = "1";
                    }

                    function selfdeco_stop() {
                      document.getElementById('selfdeco_image').style.opacity = "0";
                    }
                    selfdeco_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2011.04977">
                    <papertitle>SelfDeco: Self-Supervised Monocular Depth Completion in Challenging Indoor Environments
                    </papertitle>
                  </a>
                  <br>
                  Jaehoon Choi, <strong><u>Dongki Jung</u></strong>, Yonghan Lee, Deokhwa Kim,
                  Dinesh Manocha,
                  Donghwan Lee
                  <br>
                  <em>ICRA</em>, 2021
                  <br>
                  <!--              <a href="https://arxiv.org/abs/2011.04977">arXiv</a>-->
                  <br>
                  <p></p>
                  <p>
                    We present a novel algorithm for self-supervised monocular depth completion in challenging indoor
                    environments.
                  </p>
                </td>
              </tr>

              <tr onmouseout="safe_stop()" onmouseover="safe_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='safe_image'>
                      <br>
                      <img src='image/SAFENet.PNG' width="190">
                    </div>
                    <br>
                    <img src='image/SAFENet.PNG' width="190">
                  </div>
                  <script type="text/javascript">
                    function safe_start() {
                      document.getElementById('safe_image').style.opacity = "1";
                    }

                    function safe_stop() {
                      document.getElementById('safe_image').style.opacity = "0";
                    }
                    safe_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2010.02893">
                    <papertitle>SAFENet: Self-Supervised Monocular Depth Estimation with Semantic-Aware Feature
                      Extraction</papertitle>
                  </a>
                  <br>
                  Jaehoon Choi*, <strong><u>Dongki Jung</u></strong>*, Donghwan Lee, Changick Kim
                  <br>
                  <em>NeurIPS Workshop on Machine Learning for Autonomous Driving</em>, 2020
                  <br>
                  <!--              <a href="https://arxiv.org/abs/2010.02893">arXiv</a>-->
                  <p></p>
                  <p>
                    We propose SAFENet that is designed to leverage semantic information to overcome the limitations of
                    the photometric loss.
                  </p>
                </td>
              </tr>

              <tr onmouseout="astu_stop()" onmouseover="astu_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='astu_image'>
                      <img src='image/ASTU.PNG' width="190">
                    </div>
                    <img src='image/ASTU.PNG' width="190">
                  </div>
                  <script type="text/javascript">
                    function astu_start() {
                      document.getElementById('astu_image').style.opacity = "1";
                    }

                    function astu_stop() {
                      document.getElementById('astu_image').style.opacity = "0";
                    }
                    astu_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2010.02560.pdf">
                    <papertitle>Arbitrary Style Transfer Using Graph Instance Normalization</papertitle>
                  </a>
                  <br>
                  <strong><u>Dongki Jung</u></strong>, Seunghan Yang, Jaehoon Choi, Changick Kim
                  <br>
                  <em>ICIP</em>, 2020
                  <br>
                  <!--              <a href="https://arxiv.org/pdf/2010.02560.pdf">arXiv</a>-->
                  <p></p>
                  <p>We present a novel learnable normalization technique for style transfer using graph convolutional
                    networks.</p>
                </td>
              </tr>

              <tr onmouseout="gdpa_stop()" onmouseover="gdpa_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='gdpa_image'>
                      <br><br>
                      <img src='image/gdpa_resize.png' width="190">
                    </div>
                    <br><br>
                    <img src='image/gdpa_resize.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function gdpa_start() {
                      document.getElementById('gdpa_image').style.opacity = "1";
                    }

                    function gdpa_stop() {
                      document.getElementById('gdpa_image').style.opacity = "0";
                    }
                    gdpa_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2005.07858.pdf">
                    <papertitle>Partial Domain Adaptation Using Graph Convolutional Networks</papertitle>
                  </a>
                  <br>
                  Seunghan Yang, Youngeun Kim, <strong><u>Dongki Jung</u></strong>, Changick Kim
                  <br>
                  <em>arXiv</em>, 2020
                  <br>
                  <!--              <a href="https://arxiv.org/pdf/2005.07858.pdf">arXiv</a>-->
                  <p></p>
                  <p>We propose a graph partial domain adaptation network, which exploits Graph Convolutional Networks.
                  </p>
                </td>
              </tr>


            </tbody>
          </table>

          <!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
          <!--          <tr>-->
          <!--            <td>-->
          <!--              <heading>Service</heading>-->
          <!--            </td>-->
          <!--          </tr>-->
          <!--        </tbody></table>-->
          <!--        <table width="100%" align="center" border="0" cellpadding="20"><tbody>-->
          <!--          <tr>-->
          <!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
          <!--              <img src="image/kaist.png" alt="EE838">-->
          <!--            </td>-->
          <!--            <td width="75%" valign="center">-->
          <!--              <br>-->
          <!--              &lt;!&ndash; <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a> &ndash;&gt;-->
          <!--&lt;!&ndash;              Teaching Assistant, EE838–Special Topics in Image Engineering Optimization for Computer Vision Spring 2019&ndash;&gt;-->
          <!--              <br>-->
          <!--              <br>-->
          <!--&lt;!&ndash;              Student Tutor for Foreign Students: Introduction to Programming, CS101 2019&ndash;&gt;-->
          <!--              <br>-->
          <!--            </td>-->
          <!--          </tr>-->
          <!--        </tbody></table>-->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    <a href="https://jonbarron.info/">Thanks to Jon Barron! </a>
                    <br>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
